{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mplhep as hep\n",
    "import matplotlib.pyplot as plt\n",
    "import uproot, os, sys\n",
    "import awkward as ak\n",
    "# Get the notebook directory\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "# Add the project root to sys.path\n",
    "sys.path.append(os.path.join(notebook_dir, \"..\"))\n",
    "from utils.branches import get_branches\n",
    "from utils.plot import plot_data\n",
    "from utils.constants import trigcut, truthpkk\n",
    "from utils.data_loader import load_mc_data\n",
    "from matplotlib import rcParams\n",
    "import matplotlib as mpl\n",
    "plt.style.use(hep.style.LHCb1)\n",
    "config = {\"mathtext.fontset\":'stix'}\n",
    "rcParams.update(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({\n",
    "    # Keep the font family settings for LHCb style\n",
    "    \"font.family\": \"serif\",\n",
    "    \"font.serif\": [\"Times\", \"Computer Modern Roman\", \"DejaVu Serif\"],\n",
    "    \n",
    "    # # Increase only the size-related parameters\n",
    "    # \"figure.figsize\": (15, 10),  # Larger figure\n",
    "    # \"figure.dpi\": 100,          # Screen display\n",
    "    # \"savefig.dpi\": 300,         # Saved figure resolution\n",
    "    \n",
    "    # # # Increase font sizes while keeping LHCb style\n",
    "    \"font.size\": 12,            # Base font size (increase from default)\n",
    "    \"axes.titlesize\": 12,       # Title size\n",
    "    \"axes.labelsize\": 10,       # Axis label size\n",
    "    \"xtick.labelsize\": 12,      # X tick label size\n",
    "    \"ytick.labelsize\": 12,      # Y tick label size\n",
    "    \"legend.fontsize\": 12       # Legend font size\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MC Files being processed with trees ['DD']: ['/share/lazy/Mohamed/Bu2LambdaPPP/MC/DaVinciTuples/restripped.MC/MC16MDBu2L0barPKpKm.root:B2L0barPKpKm_DD/DecayTree', '/share/lazy/Mohamed/Bu2LambdaPPP/MC/DaVinciTuples/restripped.MC/MC16MUBu2L0barPKpKm.root:B2L0barPKpKm_DD/DecayTree', '/share/lazy/Mohamed/Bu2LambdaPPP/MC/DaVinciTuples/restripped.MC/MC17MDBu2L0barPKpKm.root:B2L0barPKpKm_DD/DecayTree', '/share/lazy/Mohamed/Bu2LambdaPPP/MC/DaVinciTuples/restripped.MC/MC17MUBu2L0barPKpKm.root:B2L0barPKpKm_DD/DecayTree', '/share/lazy/Mohamed/Bu2LambdaPPP/MC/DaVinciTuples/restripped.MC/MC18MDBu2L0barPKpKm.root:B2L0barPKpKm_DD/DecayTree', '/share/lazy/Mohamed/Bu2LambdaPPP/MC/DaVinciTuples/restripped.MC/MC18MUBu2L0barPKpKm.root:B2L0barPKpKm_DD/DecayTree']\n",
      "MC Branches being read: ['h1_P', 'h1_PT', 'h1_PE', 'h1_PX', 'h1_PY', 'h1_PZ', 'h1_ID', 'h1_TRACK_Type', 'h1_IPCHI2_OWNPV', 'h2_P', 'h2_PT', 'h2_PE', 'h2_PX', 'h2_PY', 'h2_PZ', 'h2_ID', 'h2_TRACK_Type', 'h2_IPCHI2_OWNPV', 'p_P', 'p_PT', 'p_PE', 'p_PX', 'p_PY', 'p_PZ', 'p_ID', 'p_TRACK_Type', 'p_IPCHI2_OWNPV', 'h1_MC15TuneV1_ProbNNk', 'h1_MC15TuneV1_ProbNNpi', 'h1_MC15TuneV1_ProbNNp', 'h1_MC15TuneV1_ProbNNmu', 'h2_MC15TuneV1_ProbNNk', 'h2_MC15TuneV1_ProbNNpi', 'h2_MC15TuneV1_ProbNNp', 'h2_MC15TuneV1_ProbNNmu', 'p_MC15TuneV1_ProbNNk', 'p_MC15TuneV1_ProbNNpi', 'p_MC15TuneV1_ProbNNp', 'p_MC15TuneV1_ProbNNmu', 'h1_ProbNNk', 'h1_ProbNNpi', 'h1_ProbNNp', 'h1_ProbNNmu', 'h2_ProbNNk', 'h2_ProbNNpi', 'h2_ProbNNp', 'h2_ProbNNmu', 'p_ProbNNk', 'p_ProbNNpi', 'p_ProbNNp', 'p_ProbNNmu', 'Lp_P', 'Lp_PT', 'Lp_PE', 'Lp_PX', 'Lp_PY', 'Lp_PZ', 'Lp_ID', 'Lp_TRACK_Type', 'Lpi_P', 'Lpi_PT', 'Lpi_PE', 'Lpi_PX', 'Lpi_PY', 'Lpi_PZ', 'Lpi_ID', 'Lpi_TRACK_Type', 'L0_P', 'L0_PT', 'L0_PE', 'L0_PX', 'L0_PY', 'L0_PZ', 'L0_ID', 'L0_MM', 'L0_M', 'Lp_ProbNNp', 'Lpi_ProbNNpi', 'L0_FDCHI2_ORIVX', 'L0_DIRA_OWNPV', 'Lp_MC15TuneV1_ProbNNp', 'Lpi_MC15TuneV1_ProbNNpi', 'Lp_MC15TuneV1_ProbNNpi', 'L0_ENDVERTEX_X', 'L0_ENDVERTEX_Y', 'L0_ENDVERTEX_Z', 'L0_ENDVERTEX_XERR', 'L0_ENDVERTEX_YERR', 'L0_ENDVERTEX_ZERR', 'L0_OWNPV_Z', 'L0_OWNPV_ZERR', 'L0_FD_OWNPV', 'L0_FDCHI2_OWNPV', 'L0_IPCHI2_OWNPV', 'Lp_IPCHI2_OWNPV', 'Lpi_IPCHI2_OWNPV', 'Bu_DTFL0_Lambda0_pplus_PX', 'Bu_DTFL0_Lambda0_pplus_PY', 'Bu_DTFL0_Lambda0_pplus_PZ', 'Bu_DTFL0_Lambda0_pplus_PE', 'Bu_DTFL0_Lambda0_piplus_PX', 'Bu_DTFL0_Lambda0_piplus_PY', 'Bu_DTFL0_Lambda0_piplus_PZ', 'Bu_DTFL0_Lambda0_piplus_PE', 'Bu_DTF_Lambda0_pplus_PX', 'Bu_DTF_Lambda0_pplus_PY', 'Bu_DTF_Lambda0_pplus_PZ', 'Bu_DTF_Lambda0_pplus_PE', 'Bu_DTF_Lambda0_piplus_PX', 'Bu_DTF_Lambda0_piplus_PY', 'Bu_DTF_Lambda0_piplus_PZ', 'Bu_DTF_Lambda0_piplus_PE', 'Bu_FDCHI2_OWNPV', 'nTracks', 'Bu_DTF_Lambda0_decayLength', 'Bu_DTF_Lambda0_decayLengthErr', 'Bu_ENDVERTEX_X', 'Bu_ENDVERTEX_Y', 'Bu_ENDVERTEX_Z', 'Bu_ENDVERTEX_XERR', 'Bu_ENDVERTEX_YERR', 'Bu_ENDVERTEX_ZERR', 'Bu_IPCHI2_OWNPV', 'Bu_MM', 'Bu_MMERR', 'Bu_ID', 'Bu_P', 'Bu_PT', 'Bu_PE', 'Bu_PX', 'Bu_PY', 'Bu_PZ', 'Bu_DTF_nPV', 'Bu_DTF_chi2', 'Bu_DTF_nDOF', 'Bu_DTFL0_chi2', 'Bu_DTFL0_nDOF', 'Bu_DTF_status', 'Bu_DTF_decayLength', 'Bu_DTF_decayLengthErr', 'Bu_DTFL0_ctau', 'Bu_DTFL0_ctauErr', 'Bu_DTF_ctau', 'Bu_DTF_ctauErr', 'Bu_DTFL0_M', 'Bu_DTFL0_MERR', 'Bu_DIRA_OWNPV', 'eventNumber', 'Bu_L0Global_Dec', 'Bu_L0Global_TIS', 'Bu_L0Global_TOS', 'Bu_L0HadronDecision_TIS', 'Bu_L0HadronDecision_TOS', 'Bu_L0MuonDecision_Dec', 'Bu_L0MuonDecision_TIS', 'Bu_L0MuonDecision_TOS', 'Bu_L0MuonHighDecision_Dec', 'Bu_L0MuonHighDecision_TIS', 'Bu_L0MuonHighDecision_TOS', 'Bu_L0DiMuonDecision_Dec', 'Bu_L0DiMuonDecision_TIS', 'Bu_L0DiMuonDecision_TOS', 'Bu_Hlt1TrackMVADecision_Dec', 'Bu_Hlt1TrackMVADecision_TIS', 'Bu_Hlt1TrackMVADecision_TOS', 'Bu_Hlt1TrackMVALooseDecision_Dec', 'Bu_Hlt1TrackMVALooseDecision_TIS', 'Bu_Hlt1TrackMVALooseDecision_TOS', 'Bu_Hlt1TwoTrackMVADecision_Dec', 'Bu_Hlt1TwoTrackMVADecision_TIS', 'Bu_Hlt1TwoTrackMVADecision_TOS', 'Bu_Hlt1MBNoBiasDecision_TOS', 'Bu_Hlt2Topo2BodyDecision_Dec', 'Bu_Hlt2Topo2BodyDecision_TIS', 'Bu_Hlt2Topo2BodyDecision_TOS', 'Bu_Hlt2Topo3BodyDecision_Dec', 'Bu_Hlt2Topo3BodyDecision_TIS', 'Bu_Hlt2Topo3BodyDecision_TOS', 'Bu_Hlt2Topo4BodyDecision_Dec', 'Bu_Hlt2Topo4BodyDecision_TIS', 'Bu_Hlt2Topo4BodyDecision_TOS', 'p_MC15TuneV1_ProbNNp', 'h1_MC15TuneV1_ProbNNk', 'h2_MC15TuneV1_ProbNNk', 'Bu_TRUEID']\n",
      "MC Files being processed with trees ['LL']: ['/share/lazy/Mohamed/Bu2LambdaPPP/MC/DaVinciTuples/restripped.MC/MC16MDBu2L0barPKpKm.root:B2L0barPKpKm_LL/DecayTree', '/share/lazy/Mohamed/Bu2LambdaPPP/MC/DaVinciTuples/restripped.MC/MC16MUBu2L0barPKpKm.root:B2L0barPKpKm_LL/DecayTree', '/share/lazy/Mohamed/Bu2LambdaPPP/MC/DaVinciTuples/restripped.MC/MC17MDBu2L0barPKpKm.root:B2L0barPKpKm_LL/DecayTree', '/share/lazy/Mohamed/Bu2LambdaPPP/MC/DaVinciTuples/restripped.MC/MC17MUBu2L0barPKpKm.root:B2L0barPKpKm_LL/DecayTree', '/share/lazy/Mohamed/Bu2LambdaPPP/MC/DaVinciTuples/restripped.MC/MC18MDBu2L0barPKpKm.root:B2L0barPKpKm_LL/DecayTree', '/share/lazy/Mohamed/Bu2LambdaPPP/MC/DaVinciTuples/restripped.MC/MC18MUBu2L0barPKpKm.root:B2L0barPKpKm_LL/DecayTree']\n",
      "MC Branches being read: ['h1_P', 'h1_PT', 'h1_PE', 'h1_PX', 'h1_PY', 'h1_PZ', 'h1_ID', 'h1_TRACK_Type', 'h1_IPCHI2_OWNPV', 'h2_P', 'h2_PT', 'h2_PE', 'h2_PX', 'h2_PY', 'h2_PZ', 'h2_ID', 'h2_TRACK_Type', 'h2_IPCHI2_OWNPV', 'p_P', 'p_PT', 'p_PE', 'p_PX', 'p_PY', 'p_PZ', 'p_ID', 'p_TRACK_Type', 'p_IPCHI2_OWNPV', 'h1_MC15TuneV1_ProbNNk', 'h1_MC15TuneV1_ProbNNpi', 'h1_MC15TuneV1_ProbNNp', 'h1_MC15TuneV1_ProbNNmu', 'h2_MC15TuneV1_ProbNNk', 'h2_MC15TuneV1_ProbNNpi', 'h2_MC15TuneV1_ProbNNp', 'h2_MC15TuneV1_ProbNNmu', 'p_MC15TuneV1_ProbNNk', 'p_MC15TuneV1_ProbNNpi', 'p_MC15TuneV1_ProbNNp', 'p_MC15TuneV1_ProbNNmu', 'h1_ProbNNk', 'h1_ProbNNpi', 'h1_ProbNNp', 'h1_ProbNNmu', 'h2_ProbNNk', 'h2_ProbNNpi', 'h2_ProbNNp', 'h2_ProbNNmu', 'p_ProbNNk', 'p_ProbNNpi', 'p_ProbNNp', 'p_ProbNNmu', 'Lp_P', 'Lp_PT', 'Lp_PE', 'Lp_PX', 'Lp_PY', 'Lp_PZ', 'Lp_ID', 'Lp_TRACK_Type', 'Lpi_P', 'Lpi_PT', 'Lpi_PE', 'Lpi_PX', 'Lpi_PY', 'Lpi_PZ', 'Lpi_ID', 'Lpi_TRACK_Type', 'L0_P', 'L0_PT', 'L0_PE', 'L0_PX', 'L0_PY', 'L0_PZ', 'L0_ID', 'L0_MM', 'L0_M', 'Lp_ProbNNp', 'Lpi_ProbNNpi', 'L0_FDCHI2_ORIVX', 'L0_DIRA_OWNPV', 'Lp_MC15TuneV1_ProbNNp', 'Lpi_MC15TuneV1_ProbNNpi', 'Lp_MC15TuneV1_ProbNNpi', 'L0_ENDVERTEX_X', 'L0_ENDVERTEX_Y', 'L0_ENDVERTEX_Z', 'L0_ENDVERTEX_XERR', 'L0_ENDVERTEX_YERR', 'L0_ENDVERTEX_ZERR', 'L0_OWNPV_Z', 'L0_OWNPV_ZERR', 'L0_FD_OWNPV', 'L0_FDCHI2_OWNPV', 'L0_IPCHI2_OWNPV', 'Lp_IPCHI2_OWNPV', 'Lpi_IPCHI2_OWNPV', 'Bu_DTFL0_Lambda0_pplus_PX', 'Bu_DTFL0_Lambda0_pplus_PY', 'Bu_DTFL0_Lambda0_pplus_PZ', 'Bu_DTFL0_Lambda0_pplus_PE', 'Bu_DTFL0_Lambda0_piplus_PX', 'Bu_DTFL0_Lambda0_piplus_PY', 'Bu_DTFL0_Lambda0_piplus_PZ', 'Bu_DTFL0_Lambda0_piplus_PE', 'Bu_DTF_Lambda0_pplus_PX', 'Bu_DTF_Lambda0_pplus_PY', 'Bu_DTF_Lambda0_pplus_PZ', 'Bu_DTF_Lambda0_pplus_PE', 'Bu_DTF_Lambda0_piplus_PX', 'Bu_DTF_Lambda0_piplus_PY', 'Bu_DTF_Lambda0_piplus_PZ', 'Bu_DTF_Lambda0_piplus_PE', 'Bu_FDCHI2_OWNPV', 'nTracks', 'Bu_DTF_Lambda0_decayLength', 'Bu_DTF_Lambda0_decayLengthErr', 'Bu_ENDVERTEX_X', 'Bu_ENDVERTEX_Y', 'Bu_ENDVERTEX_Z', 'Bu_ENDVERTEX_XERR', 'Bu_ENDVERTEX_YERR', 'Bu_ENDVERTEX_ZERR', 'Bu_IPCHI2_OWNPV', 'Bu_MM', 'Bu_MMERR', 'Bu_ID', 'Bu_P', 'Bu_PT', 'Bu_PE', 'Bu_PX', 'Bu_PY', 'Bu_PZ', 'Bu_DTF_nPV', 'Bu_DTF_chi2', 'Bu_DTF_nDOF', 'Bu_DTFL0_chi2', 'Bu_DTFL0_nDOF', 'Bu_DTF_status', 'Bu_DTF_decayLength', 'Bu_DTF_decayLengthErr', 'Bu_DTFL0_ctau', 'Bu_DTFL0_ctauErr', 'Bu_DTF_ctau', 'Bu_DTF_ctauErr', 'Bu_DTFL0_M', 'Bu_DTFL0_MERR', 'Bu_DIRA_OWNPV', 'eventNumber', 'Bu_L0Global_Dec', 'Bu_L0Global_TIS', 'Bu_L0Global_TOS', 'Bu_L0HadronDecision_TIS', 'Bu_L0HadronDecision_TOS', 'Bu_L0MuonDecision_Dec', 'Bu_L0MuonDecision_TIS', 'Bu_L0MuonDecision_TOS', 'Bu_L0MuonHighDecision_Dec', 'Bu_L0MuonHighDecision_TIS', 'Bu_L0MuonHighDecision_TOS', 'Bu_L0DiMuonDecision_Dec', 'Bu_L0DiMuonDecision_TIS', 'Bu_L0DiMuonDecision_TOS', 'Bu_Hlt1TrackMVADecision_Dec', 'Bu_Hlt1TrackMVADecision_TIS', 'Bu_Hlt1TrackMVADecision_TOS', 'Bu_Hlt1TrackMVALooseDecision_Dec', 'Bu_Hlt1TrackMVALooseDecision_TIS', 'Bu_Hlt1TrackMVALooseDecision_TOS', 'Bu_Hlt1TwoTrackMVADecision_Dec', 'Bu_Hlt1TwoTrackMVADecision_TIS', 'Bu_Hlt1TwoTrackMVADecision_TOS', 'Bu_Hlt1MBNoBiasDecision_TOS', 'Bu_Hlt2Topo2BodyDecision_Dec', 'Bu_Hlt2Topo2BodyDecision_TIS', 'Bu_Hlt2Topo2BodyDecision_TOS', 'Bu_Hlt2Topo3BodyDecision_Dec', 'Bu_Hlt2Topo3BodyDecision_TIS', 'Bu_Hlt2Topo3BodyDecision_TOS', 'Bu_Hlt2Topo4BodyDecision_Dec', 'Bu_Hlt2Topo4BodyDecision_TIS', 'Bu_Hlt2Topo4BodyDecision_TOS', 'p_MC15TuneV1_ProbNNp', 'h1_MC15TuneV1_ProbNNk', 'h2_MC15TuneV1_ProbNNk', 'Bu_TRUEID']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "_mc_dd = load_mc_data(\n",
    "    mc_path=\"/share/lazy/Mohamed/Bu2LambdaPPP/MC/DaVinciTuples/restripped.MC\",\n",
    "    decay_mode=\"L0barPKpKm\",\n",
    "    particles=[\"h1\", \"h2\", \"p\"],\n",
    "    additional_branches=[\n",
    "        \"p_MC15TuneV1_ProbNNp\",\n",
    "        \"h1_MC15TuneV1_ProbNNk\",\n",
    "        \"h2_MC15TuneV1_ProbNNk\",\n",
    "        \"Bu_TRUEID\"\n",
    "    ],\n",
    "    tracks=[\"DD\"], # [\"DD\", \"LL\"],\n",
    "    cuts=trigcut + truthpkk\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "_mc_ll = load_mc_data(\n",
    "    mc_path=\"/share/lazy/Mohamed/Bu2LambdaPPP/MC/DaVinciTuples/restripped.MC\",\n",
    "    decay_mode=\"L0barPKpKm\",\n",
    "    particles=[\"h1\", \"h2\", \"p\"],\n",
    "    additional_branches=[\n",
    "        \"p_MC15TuneV1_ProbNNp\",\n",
    "        \"h1_MC15TuneV1_ProbNNk\",\n",
    "        \"h2_MC15TuneV1_ProbNNk\",\n",
    "        \"Bu_TRUEID\"\n",
    "    ],\n",
    "    tracks=[\"LL\"], # [\"DD\", \"LL\"],\n",
    "    cuts=trigcut + truthpkk\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Apply the cuts to get the selection masks\\nll_mask, dd_mask, ll_summary, dd_summary = apply_cuts_to_samples(mc_ll, mc_dd)\\n\\n# Apply the masks to get the selected events\\nmc_ll_selected = apply_mask_to_data(mc_ll, ll_mask)\\nmc_dd_selected = apply_mask_to_data(mc_dd, dd_mask)\\n\\n# Cut efficiency plotting removed as requested\\n\\n# Now you can proceed with analysis using the selected samples\\n# Further operations with mc_ll_selected and mc_dd_selected...\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import awkward as ak\n",
    "from collections import OrderedDict\n",
    "\n",
    "def apply_selection_cuts(events, track_type='LL'):\n",
    "    \"\"\"\n",
    "    Apply selection cuts to B+ → Λ0 h1 h2 samples based on specific criteria\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    events : awkward.Array or dict-like object\n",
    "        Events from uproot containing the MC sample\n",
    "    track_type : str\n",
    "        Track type, either 'LL' (Long-Long) or 'DD' (Downstream-Downstream)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    numpy.ndarray\n",
    "        Boolean mask of selected events\n",
    "    dict\n",
    "        Summary of the cuts applied\n",
    "    \"\"\"\n",
    "    # Initialize mask with all True\n",
    "    mask = np.ones(len(events), dtype=bool)\n",
    "    \n",
    "    # Track the cuts for debugging and reporting\n",
    "    cuts_summary = OrderedDict()\n",
    "    initial_events = len(events)\n",
    "    \n",
    "    # ===== p (Proton) Cuts =====\n",
    "    # MC15TuneV1_ProbNNp > 0.05\n",
    "    p_prob_cut = events['p_MC15TuneV1_ProbNNp'] > 0.05\n",
    "    mask = mask & p_prob_cut\n",
    "    cuts_summary['proton_prob_cut'] = np.sum(p_prob_cut)\n",
    "    \n",
    "    # ===== Λ0 Cuts =====\n",
    "    \n",
    "    # ΔZ > 20 mm (difference between Lambda decay vertex and primary vertex)\n",
    "    delta_z = events['L0_ENDVERTEX_Z'] - events['L0_OWNPV_Z']\n",
    "    delta_z_cut = delta_z > 20\n",
    "    mask = mask & delta_z_cut\n",
    "    cuts_summary['delta_z_cut'] = np.sum(delta_z_cut)\n",
    "    \n",
    "    # χ²FD > 45 (Lambda flight distance chi2)\n",
    "    fd_chi2_cut = events['L0_FDCHI2_OWNPV'] > 45\n",
    "    mask = mask & fd_chi2_cut\n",
    "    cuts_summary['fd_chi2_cut'] = np.sum(fd_chi2_cut)\n",
    "    \n",
    "    # |m(pπ⁻) - 1115.6| < 6 MeV/c²\n",
    "    lambda_mass_diff = np.abs(events['L0_M'] - 1115.6)\n",
    "    lambda_mass_cut = lambda_mass_diff < 6\n",
    "    mask = mask & lambda_mass_cut\n",
    "    cuts_summary['lambda_mass_cut'] = np.sum(lambda_mass_cut)\n",
    "    \n",
    "    # Lp_MC15TuneV1_ProbNNp > 0.2\n",
    "    lp_prob_cut = events['Lp_MC15TuneV1_ProbNNp'] > 0.2\n",
    "    mask = mask & lp_prob_cut\n",
    "    cuts_summary['lp_prob_cut'] = np.sum(lp_prob_cut)\n",
    "    \n",
    "    # K_s veto cut removed as requested\n",
    "    \n",
    "    # ===== B⁺ Cuts =====\n",
    "    \n",
    "    # pT > 3000 MeV/c\n",
    "    b_pt_cut = events['Bu_PT'] > 3000\n",
    "    mask = mask & b_pt_cut\n",
    "    cuts_summary['b_pt_cut'] = np.sum(b_pt_cut)\n",
    "    \n",
    "    # χ²DTF < 30 & Converged (DTF = Decay Tree Fitter)\n",
    "    dtf_chi2 = events['Bu_DTF_chi2']\n",
    "    dtf_chi2_cut = (dtf_chi2 < 30) \n",
    "    mask = mask & dtf_chi2_cut\n",
    "    cuts_summary['dtf_chi2_cut'] = np.sum(dtf_chi2_cut)\n",
    "    \n",
    "    # χ²IP < 10 (Impact Parameter Chi2)\n",
    "    ip_chi2_cut = events['Bu_IPCHI2_OWNPV'] < 10\n",
    "    mask = mask & ip_chi2_cut\n",
    "    cuts_summary['ip_chi2_cut'] = np.sum(ip_chi2_cut)\n",
    "    \n",
    "    # χ²FD > 175 (Flight Distance Chi2)\n",
    "    b_fd_chi2_cut = events['Bu_FDCHI2_OWNPV'] > 175\n",
    "    mask = mask & b_fd_chi2_cut\n",
    "    cuts_summary['b_fd_chi2_cut'] = np.sum(b_fd_chi2_cut)\n",
    "    \n",
    "    # Print selection summary\n",
    "    selected_events = np.sum(mask)\n",
    "    print(f\"Selection summary for {track_type} sample:\")\n",
    "    print(f\"Initial events: {initial_events}\")\n",
    "    for cut_name, cut_count in cuts_summary.items():\n",
    "        print(f\"  {cut_name}: {cut_count} / {initial_events} ({cut_count/initial_events:.2%})\")\n",
    "    print(f\"Final selected events: {selected_events} / {initial_events} ({selected_events/initial_events:.2%})\")\n",
    "    \n",
    "    return mask, cuts_summary\n",
    "\n",
    "def apply_cuts_to_samples(mc_ll, mc_dd):\n",
    "    \"\"\"\n",
    "    Apply selection cuts to both LL and DD samples\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    mc_ll : awkward.Array or dict-like object\n",
    "        Long-Long track type MC sample\n",
    "    mc_dd : awkward.Array or dict-like object\n",
    "        Downstream-Downstream track type MC sample\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (mc_ll_mask, mc_dd_mask, ll_cuts_summary, dd_cuts_summary)\n",
    "    \"\"\"\n",
    "    # Apply cuts to LL sample\n",
    "    ll_mask, ll_cuts_summary = apply_selection_cuts(mc_ll, track_type='LL')\n",
    "    \n",
    "    # Apply cuts to DD sample\n",
    "    dd_mask, dd_cuts_summary = apply_selection_cuts(mc_dd, track_type='DD')\n",
    "    \n",
    "    # Print comparison between LL and DD\n",
    "    ll_total = len(mc_ll)\n",
    "    dd_total = len(mc_dd)\n",
    "    ll_selected = np.sum(ll_mask)\n",
    "    dd_selected = np.sum(dd_mask)\n",
    "    \n",
    "    print(\"\\nComparison between LL and DD selection efficiency:\")\n",
    "    print(f\"LL: {ll_selected}/{ll_total} ({ll_selected/ll_total:.2%})\")\n",
    "    print(f\"DD: {dd_selected}/{dd_total} ({dd_selected/dd_total:.2%})\")\n",
    "    \n",
    "    return ll_mask, dd_mask, ll_cuts_summary, dd_cuts_summary\n",
    "\n",
    "def apply_mask_to_data(events, mask):\n",
    "    \"\"\"\n",
    "    Apply a boolean mask to event data\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    events : awkward.Array or dict-like object\n",
    "        Event data\n",
    "    mask : numpy.ndarray\n",
    "        Boolean mask to apply\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    awkward.Array or dict-like object\n",
    "        Selected events\n",
    "    \"\"\"\n",
    "    if hasattr(events, 'mask'):\n",
    "        # For awkward arrays\n",
    "        return events[mask]\n",
    "    else:\n",
    "        # For dictionary-like objects\n",
    "        selected = {}\n",
    "        for key, array in events.items():\n",
    "            selected[key] = array[mask]\n",
    "        return selected\n",
    "\n",
    "# Plot function removed as requested\n",
    "\n",
    "\n",
    "# Usage example:\n",
    "\"\"\"\n",
    "# Apply the cuts to get the selection masks\n",
    "ll_mask, dd_mask, ll_summary, dd_summary = apply_cuts_to_samples(mc_ll, mc_dd)\n",
    "\n",
    "# Apply the masks to get the selected events\n",
    "mc_ll_selected = apply_mask_to_data(mc_ll, ll_mask)\n",
    "mc_dd_selected = apply_mask_to_data(mc_dd, dd_mask)\n",
    "\n",
    "# Cut efficiency plotting removed as requested\n",
    "\n",
    "# Now you can proceed with analysis using the selected samples\n",
    "# Further operations with mc_ll_selected and mc_dd_selected...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection summary for LL sample:\n",
      "Initial events: 30616\n",
      "  proton_prob_cut: 30526 / 30616 (99.71%)\n",
      "  delta_z_cut: 29768 / 30616 (97.23%)\n",
      "  fd_chi2_cut: 30440 / 30616 (99.43%)\n",
      "  lambda_mass_cut: 29860 / 30616 (97.53%)\n",
      "  lp_prob_cut: 29837 / 30616 (97.46%)\n",
      "  b_pt_cut: 29978 / 30616 (97.92%)\n",
      "  dtf_chi2_cut: 29693 / 30616 (96.99%)\n",
      "  ip_chi2_cut: 30385 / 30616 (99.25%)\n",
      "  b_fd_chi2_cut: 29268 / 30616 (95.60%)\n",
      "Final selected events: 25377 / 30616 (82.89%)\n",
      "Selection summary for DD sample:\n",
      "Initial events: 77067\n",
      "  proton_prob_cut: 76856 / 77067 (99.73%)\n",
      "  delta_z_cut: 77025 / 77067 (99.95%)\n",
      "  fd_chi2_cut: 72485 / 77067 (94.05%)\n",
      "  lambda_mass_cut: 73883 / 77067 (95.87%)\n",
      "  lp_prob_cut: 73492 / 77067 (95.36%)\n",
      "  b_pt_cut: 76641 / 77067 (99.45%)\n",
      "  dtf_chi2_cut: 74596 / 77067 (96.79%)\n",
      "  ip_chi2_cut: 76452 / 77067 (99.20%)\n",
      "  b_fd_chi2_cut: 73190 / 77067 (94.97%)\n",
      "Final selected events: 60356 / 77067 (78.32%)\n",
      "\n",
      "Comparison between LL and DD selection efficiency:\n",
      "LL: 25377/30616 (82.89%)\n",
      "DD: 60356/77067 (78.32%)\n"
     ]
    }
   ],
   "source": [
    "selected_ll, selected_dd, ll_summary, dd_summary = apply_cuts_to_samples(_mc_ll, _mc_dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Plot all selection variables for LL and DD samples separately\\nplot_selection_variables_separate(mc_ll, mc_dd, output_prefix=\"selection_variables\")\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import awkward as ak\n",
    "\n",
    "def plot_selection_variables_separate(mc_ll, mc_dd, output_prefix=\"selection_variables\"):\n",
    "    \"\"\"\n",
    "    Plot selection variables for LL and DD samples in separate files\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    mc_ll : awkward.Array\n",
    "        Long-Long track type MC sample\n",
    "    mc_dd : awkward.Array\n",
    "        Downstream-Downstream track type MC sample\n",
    "    output_prefix : str\n",
    "        Prefix for output files\n",
    "    \"\"\"\n",
    "    # Define variables to plot and their properties\n",
    "    variables = [\n",
    "        {\n",
    "            'name': 'p_MC15TuneV1_ProbNNp',\n",
    "            'label': 'p_MC15TuneV1_ProbNNp',\n",
    "            'cut_value': 0.05,\n",
    "            'cut_type': '>'\n",
    "        },\n",
    "        {\n",
    "            'name': 'L0_FDCHI2_OWNPV',\n",
    "            'label': 'Lambda χ²FD',\n",
    "            'cut_value': 45,\n",
    "            'cut_type': '>'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Lp_MC15TuneV1_ProbNNp',\n",
    "            'label': 'Lp_MC15TuneV1_ProbNNp',\n",
    "            'cut_value': 0.2,\n",
    "            'cut_type': '>'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Bu_PT',\n",
    "            'label': 'B+ pT [MeV/c]',\n",
    "            'cut_value': 3000,\n",
    "            'cut_type': '>'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Bu_IPCHI2_OWNPV',\n",
    "            'label': 'B+ χ²IP',\n",
    "            'cut_value': 10,\n",
    "            'cut_type': '<'\n",
    "        },\n",
    "        {\n",
    "            'name': 'Bu_FDCHI2_OWNPV',\n",
    "            'label': 'B+ χ²FD',\n",
    "            'cut_value': 175,\n",
    "            'cut_type': '>'\n",
    "        },\n",
    "        {\n",
    "            'name': 'h1_ProbNNk',\n",
    "            'label': 'h1_ProbNNk',\n",
    "            'cut_value': 0.2,\n",
    "            'cut_type': '>'\n",
    "        },\n",
    "        {\n",
    "            'name': 'h2_ProbNNk',\n",
    "            'label': 'h2_ProbNNk',\n",
    "            'cut_value': 0.2,\n",
    "            'cut_type': '>'\n",
    "        },\n",
    "        # We'll handle Bu_DTF_chi2 separately\n",
    "    ]\n",
    "    \n",
    "    # Add delta_z calculation separately\n",
    "    delta_z = {\n",
    "        'name': 'delta_z',\n",
    "        'label': 'ΔZ [mm]',\n",
    "        'cut_value': 20,\n",
    "        'cut_type': '>'\n",
    "    }\n",
    "    \n",
    "    # Add Bu_DTF_chi2 separately with special handling\n",
    "    bu_dtf_chi2 = {\n",
    "        'name': 'Bu_DTF_chi2',\n",
    "        'label': 'B+ χ²DTF',\n",
    "        'cut_value': 30,\n",
    "        'cut_type': '<'\n",
    "    }\n",
    "    \n",
    "    # Add KK product separately\n",
    "    kk_product = {\n",
    "        'name': 'kk_product',\n",
    "        'label': 'h1_ProbNNk × h2_ProbNNk',\n",
    "        'cut_value': 0.2,\n",
    "        'cut_type': '>'\n",
    "    }\n",
    "    \n",
    "    # Create figure and axes for LL\n",
    "    n_vars = len(variables) + 3  # +3 for delta_z, Bu_DTF_chi2, and kk_product\n",
    "    n_cols = 3\n",
    "    n_rows = (n_vars + n_cols - 1) // n_cols\n",
    "    \n",
    "    # Create separate figures for LL and DD\n",
    "    fig_ll, axes_ll = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows))\n",
    "    axes_ll = axes_ll.flatten()\n",
    "    \n",
    "    fig_dd, axes_dd = plt.subplots(n_rows, n_cols, figsize=(15, 4 * n_rows))\n",
    "    axes_dd = axes_dd.flatten()\n",
    "    \n",
    "    # Extract the delta_z variable\n",
    "    try:\n",
    "        ll_delta_z = np.array(ak.to_numpy(mc_ll['L0_ENDVERTEX_Z']) - ak.to_numpy(mc_ll['L0_OWNPV_Z']))\n",
    "        dd_delta_z = np.array(ak.to_numpy(mc_dd['L0_ENDVERTEX_Z']) - ak.to_numpy(mc_dd['L0_OWNPV_Z']))\n",
    "        \n",
    "        # Process delta_z \n",
    "        process_variable_single(axes_ll[0], ll_delta_z, delta_z, \"LL\")\n",
    "        process_variable_single(axes_dd[0], dd_delta_z, delta_z, \"DD\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing delta_z: {e}\")\n",
    "        axes_ll[0].text(0.5, 0.5, f\"Error processing delta_z\", ha='center', va='center', transform=axes_ll[0].transAxes)\n",
    "        axes_dd[0].text(0.5, 0.5, f\"Error processing delta_z\", ha='center', va='center', transform=axes_dd[0].transAxes)\n",
    "    \n",
    "    # Process each standard variable\n",
    "    for i, var_info in enumerate(variables):\n",
    "        try:\n",
    "            var_name = var_info['name']\n",
    "            \n",
    "            # Convert to numpy arrays to avoid awkward array issues\n",
    "            try:\n",
    "                ll_data = np.array(ak.to_numpy(mc_ll[var_name]))\n",
    "                dd_data = np.array(ak.to_numpy(mc_dd[var_name]))\n",
    "                \n",
    "                # Process the variable for each plot separately\n",
    "                process_variable_single(axes_ll[i+1], ll_data, var_info, \"LL\")\n",
    "                process_variable_single(axes_dd[i+1], dd_data, var_info, \"DD\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting {var_name}: {e}\")\n",
    "                axes_ll[i+1].text(0.5, 0.5, f\"Error extracting {var_name}\", \n",
    "                           ha='center', va='center', transform=axes_ll[i+1].transAxes)\n",
    "                axes_dd[i+1].text(0.5, 0.5, f\"Error extracting {var_name}\", \n",
    "                           ha='center', va='center', transform=axes_dd[i+1].transAxes)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing variable {i}: {e}\")\n",
    "            if i+1 < len(axes_ll):\n",
    "                axes_ll[i+1].text(0.5, 0.5, f\"Error in processing\", \n",
    "                           ha='center', va='center', transform=axes_ll[i+1].transAxes)\n",
    "                axes_dd[i+1].text(0.5, 0.5, f\"Error in processing\", \n",
    "                           ha='center', va='center', transform=axes_dd[i+1].transAxes)\n",
    "    \n",
    "    # Special handling for Bu_DTF_chi2\n",
    "    try:\n",
    "        # Try to get the first element from potentially irregular array structure\n",
    "        ll_dtf_chi2 = []\n",
    "        dd_dtf_chi2 = []\n",
    "        \n",
    "        # Handle irregular arrays by getting first element\n",
    "        for item in mc_ll[\"Bu_DTF_chi2\"]:\n",
    "            if ak.count(item) > 0:  # Check if the array is not empty\n",
    "                ll_dtf_chi2.append(float(item[0]))  # Take the first element\n",
    "            else:\n",
    "                ll_dtf_chi2.append(np.nan)  # Use NaN for empty arrays\n",
    "                \n",
    "        for item in mc_dd[\"Bu_DTF_chi2\"]:\n",
    "            if ak.count(item) > 0:\n",
    "                dd_dtf_chi2.append(float(item[0]))\n",
    "            else:\n",
    "                dd_dtf_chi2.append(np.nan)\n",
    "        \n",
    "        # Convert to numpy arrays and remove NaN values\n",
    "        ll_dtf_chi2 = np.array(ll_dtf_chi2)\n",
    "        dd_dtf_chi2 = np.array(dd_dtf_chi2)\n",
    "        \n",
    "        ll_dtf_chi2 = ll_dtf_chi2[~np.isnan(ll_dtf_chi2)]\n",
    "        dd_dtf_chi2 = dd_dtf_chi2[~np.isnan(dd_dtf_chi2)]\n",
    "        \n",
    "        # Process Bu_DTF_chi2\n",
    "        process_variable_single(axes_ll[len(variables)+1], ll_dtf_chi2, bu_dtf_chi2, \"LL\")\n",
    "        process_variable_single(axes_dd[len(variables)+1], dd_dtf_chi2, bu_dtf_chi2, \"DD\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Bu_DTF_chi2: {e}\")\n",
    "        axes_ll[len(variables)+1].text(0.5, 0.5, f\"Error processing Bu_DTF_chi2: {e}\", \n",
    "                       ha='center', va='center', transform=axes_ll[len(variables)+1].transAxes)\n",
    "        axes_dd[len(variables)+1].text(0.5, 0.5, f\"Error processing Bu_DTF_chi2: {e}\", \n",
    "                       ha='center', va='center', transform=axes_dd[len(variables)+1].transAxes)\n",
    "    \n",
    "    # Special handling for KK product\n",
    "    try:\n",
    "        # Get the individual kaon ID probabilities\n",
    "        ll_h1_probnnk = np.array(ak.to_numpy(mc_ll['h1_ProbNNk']))\n",
    "        ll_h2_probnnk = np.array(ak.to_numpy(mc_ll['h2_ProbNNk']))\n",
    "        dd_h1_probnnk = np.array(ak.to_numpy(mc_dd['h1_ProbNNk']))\n",
    "        dd_h2_probnnk = np.array(ak.to_numpy(mc_dd['h2_ProbNNk']))\n",
    "        \n",
    "        # Calculate the product\n",
    "        ll_kk_product = ll_h1_probnnk * ll_h2_probnnk\n",
    "        dd_kk_product = dd_h1_probnnk * dd_h2_probnnk\n",
    "        \n",
    "        # Process KK product\n",
    "        process_variable_single(axes_ll[len(variables)+2], ll_kk_product, kk_product, \"LL\")\n",
    "        process_variable_single(axes_dd[len(variables)+2], dd_kk_product, kk_product, \"DD\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing KK product: {e}\")\n",
    "        axes_ll[len(variables)+2].text(0.5, 0.5, f\"Error processing KK product: {e}\", \n",
    "                       ha='center', va='center', transform=axes_ll[len(variables)+2].transAxes)\n",
    "        axes_dd[len(variables)+2].text(0.5, 0.5, f\"Error processing KK product: {e}\", \n",
    "                       ha='center', va='center', transform=axes_dd[len(variables)+2].transAxes)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Bu_DTF_chi2: {e}\")\n",
    "        axes_ll[len(variables)+1].text(0.5, 0.5, f\"Error processing Bu_DTF_chi2: {e}\", \n",
    "                       ha='center', va='center', transform=axes_ll[len(variables)+1].transAxes)\n",
    "        axes_dd[len(variables)+1].text(0.5, 0.5, f\"Error processing Bu_DTF_chi2: {e}\", \n",
    "                       ha='center', va='center', transform=axes_dd[len(variables)+1].transAxes)\n",
    "    \n",
    "    # Handle any unused axes\n",
    "    for i in range(n_vars, len(axes_ll)):\n",
    "        axes_ll[i].set_visible(False)\n",
    "        axes_dd[i].set_visible(False)\n",
    "    \n",
    "    # Add overall titles\n",
    "    fig_ll.suptitle(\"Selection Variables - LL Sample\", fontsize=16)\n",
    "    fig_dd.suptitle(\"Selection Variables - DD Sample\", fontsize=16)\n",
    "    \n",
    "    # Adjust layout\n",
    "    fig_ll.tight_layout()\n",
    "    plt.figure(fig_ll.number)\n",
    "    plt.subplots_adjust(top=0.95)\n",
    "    \n",
    "    fig_dd.tight_layout()\n",
    "    plt.figure(fig_dd.number)\n",
    "    plt.subplots_adjust(top=0.95)\n",
    "    \n",
    "    # Save figures\n",
    "    ll_filename = f\"{output_prefix}_LL_mc.pdf\"\n",
    "    dd_filename = f\"{output_prefix}_DD_mc.pdf\"\n",
    "    \n",
    "    plt.figure(fig_ll.number)\n",
    "    plt.savefig(ll_filename, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.figure(fig_dd.number)\n",
    "    plt.savefig(dd_filename, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    plt.close(fig_ll)\n",
    "    plt.close(fig_dd)\n",
    "    \n",
    "    print(f\"LL plot saved to {ll_filename}\")\n",
    "    print(f\"DD plot saved to {dd_filename}\")\n",
    "    return\n",
    "\n",
    "def process_variable_single(ax, data, var_info, sample_type):\n",
    "    \"\"\"\n",
    "    Process and plot a single variable for a single sample\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    ax : matplotlib.axes.Axes\n",
    "        Axes to plot on\n",
    "    data : numpy.ndarray\n",
    "        Data from sample\n",
    "    var_info : dict\n",
    "        Variable information (name, label, cut_value, cut_type)\n",
    "    sample_type : str\n",
    "        Sample type (\"LL\" or \"DD\")\n",
    "    \"\"\"\n",
    "    var_name = var_info['name']\n",
    "    var_label = var_info['label']\n",
    "    cut_value = var_info['cut_value']\n",
    "    cut_type = var_info['cut_type']\n",
    "    \n",
    "    # Calculate pass percentage\n",
    "    if cut_type == '>':\n",
    "        pass_percent = (data > cut_value).sum() / len(data) * 100\n",
    "    else:  # '<'\n",
    "        pass_percent = (data < cut_value).sum() / len(data) * 100\n",
    "    \n",
    "    # Create bins for histogram\n",
    "    min_val = np.min(data)\n",
    "    max_val = np.max(data)\n",
    "    \n",
    "    # Special handling for some variables with extreme ranges\n",
    "    if max_val - min_val > 1000 and 'PT' in var_name:\n",
    "        # For PT variables, focus on the important range\n",
    "        min_val = max(0, min_val)\n",
    "        max_val = min(10000, max_val)\n",
    "    elif max_val - min_val > 1000 and 'CHI2' in var_name:\n",
    "        # For CHI2 variables, focus on the important range\n",
    "        min_val = max(0, min_val)\n",
    "        max_val = min(500, max_val)\n",
    "    \n",
    "    # Add padding to range\n",
    "    range_padding = (max_val - min_val) * 0.1\n",
    "    hist_range = (min_val - range_padding, max_val + range_padding)\n",
    "    \n",
    "    # Set number of bins based on data range\n",
    "    if max_val - min_val > 100:\n",
    "        bins = 50\n",
    "    else:\n",
    "        bins = 30\n",
    "    \n",
    "    # Create histogram with raw counts (not density)\n",
    "    hist, bins = np.histogram(data, bins=bins, range=hist_range, density=False)\n",
    "    \n",
    "    # Calculate bin centers\n",
    "    centers = (bins[:-1] + bins[1:]) / 2\n",
    "    \n",
    "    # Plot histograms as step plots (cleaner than bars)\n",
    "    color = 'blue' if sample_type == 'LL' else 'green'\n",
    "    ax.step(centers, hist, where='mid', color=color, linewidth=2)\n",
    "    \n",
    "    # Add vertical line at cut value\n",
    "    ymin, ymax = 0, np.max(hist) * 1.1\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.vlines(cut_value, ymin, ymax, colors='red', linestyles='dashed', linewidth=2)\n",
    "    \n",
    "    # Add cut text at the top of the graph\n",
    "    ax.text(\n",
    "        0.5, \n",
    "        0.95, \n",
    "        f\"Cut: {cut_type} {cut_value} ({pass_percent:.1f}% pass)\", \n",
    "        transform=ax.transAxes, \n",
    "        verticalalignment='top', \n",
    "        horizontalalignment='center',\n",
    "        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8)\n",
    "    )\n",
    "    \n",
    "    # Set title and labels\n",
    "    ax.set_title(f\"{var_label} - {sample_type}\")\n",
    "    ax.set_xlabel(var_label)\n",
    "    ax.set_ylabel('Events')\n",
    "    \n",
    "    return\n",
    "\n",
    "# Example usage:\n",
    "\"\"\"\n",
    "# Plot all selection variables for LL and DD samples separately\n",
    "plot_selection_variables_separate(mc_ll, mc_dd, output_prefix=\"selection_variables\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_ll = _mc_ll\n",
    "mc_dd = _mc_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_selection_variables_separate(mc_ll, mc_dd, output_prefix=\"selection_variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
